{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michal\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing provided by AlQuraishi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_AAS = 20\n",
    "NUM_DIMENSIONS = 3\n",
    "\n",
    "def masking_matrix(mask, name=None):\n",
    "    \"\"\" Constructs a masking matrix to zero out pairwise distances due to missing residues or padding. \n",
    "\n",
    "    Args:\n",
    "        mask: 0/1 vector indicating whether a position should be masked (0) or not (1)\n",
    "\n",
    "    Returns:\n",
    "        A square matrix with all 1s except for rows and cols whose corresponding indices in mask are set to 0.\n",
    "        [MAX_SEQ_LENGTH, MAX_SEQ_LENGTH]\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'masking_matrix', [mask]) as scope:\n",
    "        mask = tf.convert_to_tensor(mask, name='mask')\n",
    "\n",
    "        mask = tf.expand_dims(mask, 0)\n",
    "        base = tf.ones([tf.size(mask), tf.size(mask)])\n",
    "        matrix_mask = base * mask * tf.transpose(mask)\n",
    "\n",
    "        return matrix_mask\n",
    "        \n",
    "def read_protein(filename_queue, max_length, num_evo_entries=21, name=None):\n",
    "    \"\"\" Reads and parses a ProteinNet TF Record. \n",
    "\n",
    "        Primary sequences are mapped onto 20-dimensional one-hot vectors.\n",
    "        Evolutionary sequences are mapped onto num_evo_entries-dimensional real-valued vectors.\n",
    "        Secondary structures are mapped onto ints indicating one of 8 class labels.\n",
    "        Tertiary coordinates are flattened so that there are 3 times as many coordinates as \n",
    "        residues.\n",
    "\n",
    "        Evolutionary, secondary, and tertiary entries are optional.\n",
    "\n",
    "    Args:\n",
    "        filename_queue: TF queue for reading files\n",
    "        max_length:     Maximum length of sequence (number of residues) [MAX_LENGTH]. Not a \n",
    "                        TF tensor and is thus a fixed value.\n",
    "\n",
    "    Returns:\n",
    "        id: string identifier of record\n",
    "        one_hot_primary: AA sequence as one-hot vectors\n",
    "        evolutionary: PSSM sequence as vectors\n",
    "        secondary: DSSP sequence as int class labels\n",
    "        tertiary: 3D coordinates of structure\n",
    "        matrix_mask: Masking matrix to zero out pairwise distances in the masked regions\n",
    "        pri_length: Length of amino acid sequence\n",
    "        keep: True if primary length is less than or equal to max_length\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'read_protein', []) as scope:\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "        context, features = tf.parse_single_sequence_example(serialized_example,\n",
    "                                context_features={'id': tf.FixedLenFeature((1,), tf.string)},\n",
    "                                sequence_features={\n",
    "                                    'primary':      tf.FixedLenSequenceFeature((1,),               tf.int64),\n",
    "                                    'evolutionary': tf.FixedLenSequenceFeature((num_evo_entries,), tf.float32, allow_missing=True),\n",
    "                                    'secondary':    tf.FixedLenSequenceFeature((1,),               tf.int64,   allow_missing=True),\n",
    "                                    'tertiary':     tf.FixedLenSequenceFeature((NUM_DIMENSIONS,),  tf.float32, allow_missing=True),\n",
    "                                    'mask':         tf.FixedLenSequenceFeature((1,),               tf.float32, allow_missing=True)})\n",
    "        id_ = context['id'][0]\n",
    "        primary =   tf.to_int32(features['primary'][:, 0])\n",
    "        evolutionary =          features['evolutionary']\n",
    "        secondary = tf.to_int32(features['secondary'][:, 0])\n",
    "        tertiary =              features['tertiary']\n",
    "        mask =                  features['mask'][:, 0]\n",
    "\n",
    "        pri_length = tf.size(primary)\n",
    "        keep = pri_length <= max_length\n",
    "\n",
    "        one_hot_primary = tf.one_hot(primary, NUM_AAS)\n",
    "\n",
    "        # Generate tertiary masking matrix--if mask is missing then assume all residues are present\n",
    "        mask = tf.cond(tf.not_equal(tf.size(mask), 0), lambda: mask, lambda: tf.ones([pri_length]))\n",
    "        ter_mask = masking_matrix(mask, name='ter_mask')        \n",
    "\n",
    "        return id_, one_hot_primary, evolutionary, secondary, tertiary, ter_mask, pri_length, keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of how to calculate dihedral angles and set up a bidirecitonal lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_rad2deg(rad):\n",
    "    pi_on_180 = 0.017453292519943295\n",
    "    return rad / pi_on_180\n",
    "\n",
    "# takes a 4-dimensional tensor (N, K, 4, 3) and outputs (N, K, 3) angles\n",
    "def dihedral_tf3(p):\n",
    "    p0 = tf.gather(p, 0, axis=2)\n",
    "    p1 = tf.gather(p, 1, axis=2)\n",
    "    p2 = tf.gather(p, 2, axis=2)\n",
    "    p3 = tf.gather(p, 3, axis=2)\n",
    "    \n",
    "    b0 = -1.0 * (tf.subtract(p1, p0))\n",
    "    b1 = tf.subtract(p2, p1)\n",
    "    b2 = tf.subtract(p3, p2)\n",
    "    \n",
    "    b1 = tf.divide(b1, tf.norm(b1, axis=2, keepdims=True))\n",
    "    b1 = tf.where(tf.is_nan(b1), tf.ones_like(b1), b1) # what to do when norm is 0?\n",
    "    \n",
    "    v = tf.subtract(b0, tf.einsum('bi,bij->bij', tf.einsum('bij,bij->bi', b0, b1), b1))\n",
    "    w = tf.subtract(b2, tf.einsum('bi,bij->bij', tf.einsum('bij,bij->bi', b2, b1), b1))\n",
    "    \n",
    "    x = tf.reduce_sum( tf.multiply( v, w ), 2, keepdims=True )\n",
    "    y = tf.reduce_sum( tf.multiply( tf.cross(b1, v), w ), 2, keepdims=True )\n",
    "\n",
    "    return tf_rad2deg(tf.atan2(y,x))\n",
    "\n",
    "# euclidean_coordinates are of shape (batch_size, protein_length, 3)\n",
    "def dihedral_pipeline(euclidean_coordinates, batch_size, protein_length):\n",
    "    # chooses all possible slices of length 4\n",
    "    euclidean_coordinates = euclidean_coordinates[:,:,:,None]\n",
    "    all_4_len_slices_euc_coord = tf.extract_image_patches(euclidean_coordinates,\n",
    "      ksizes=[1, 4, 3, 1],\n",
    "      strides=[1, 1, 1, 1],\n",
    "      rates=[1, 1, 1, 1],\n",
    "      padding='VALID')\n",
    "    all_4_len_slices_euc_coord = tf.reshape(tf.squeeze(all_4_len_slices_euc_coord), [batch_size, -1, 4, 3])\n",
    "\n",
    "    # calculates torsional angles on the entire batch\n",
    "    dihedral_angles = dihedral_tf3(all_4_len_slices_euc_coord)\n",
    "\n",
    "    # adds 3 zeros at the end because I can't calculate the angle of\n",
    "    # the last 3 atmos (need at least 4 atoms to calculate an angle)\n",
    "    padding = tf.constant([[0, 0], [0,3], [0,0]])\n",
    "    dihedral_angles = tf.pad(dihedral_angles, padding)\n",
    "\n",
    "    # reshaping the angles (because input is 3 times the length of normal protein)\n",
    "    dihedral_angles_shape = tf.gather(tf.shape(dihedral_angles), [0,1])\n",
    "    dihedral_angles = tf.reshape(dihedral_angles, shape=dihedral_angles_shape)\n",
    "    return tf.reshape(dihedral_angles, shape=(tf.gather(dihedral_angles_shape, 0), protein_length, 3))\n",
    "    \n",
    "# helper for setting up the bidirectional, multilayer lstm\n",
    "def bidirectional_lstm(input_data, num_layers, rnn_size, keep_prob, lengths):\n",
    "    output = input_data\n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer),reuse=tf.AUTO_REUSE):\n",
    "\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.truncated_normal_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.truncated_normal_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, input_keep_prob = keep_prob)\n",
    "\n",
    "            outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                              cell_bw, \n",
    "                                                              output,\n",
    "                                                              dtype=tf.float32,\n",
    "                                                              sequence_length=lengths)\n",
    "            output = tf.concat(outputs,2)\n",
    "\n",
    "    return output\n",
    "\n",
    "# helper to count number of records in a TF record file\n",
    "def get_num_records(tf_record_file):\n",
    "    return len([x for x in tf.python_io.tf_record_iterator(tf_record_file)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and load training paths. Count the number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\30\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\50\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\70\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\90\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\95\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\100\\\\*']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108670"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose paths from which to get training data\n",
    "percentages = [30, 50, 70, 90, 95, 100]\n",
    "main_path = \"C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\\"\n",
    "paths = [main_path + str(perc) + '\\\\*' for perc in percentages]\n",
    "print(paths)\n",
    "# load all the file names from these paths\n",
    "base_names = [glob.glob(a_path) for a_path in paths]\n",
    "base_names = list(np.concatenate(base_names))\n",
    "\n",
    "training_samples = np.sum([get_num_records(file) for file in base_names])\n",
    "training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\30\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\50\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\70\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\90\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\95\\\\*', 'C:\\\\Users\\\\Michal\\\\Desktop\\\\ITU NLP\\\\casp7\\\\training\\\\100\\\\*']\n",
      "108670\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# the input pipeline should be rewritten using\n",
    "# the new dataset api that tesnorflow introduced\n",
    "\n",
    "# parameters for the training and\n",
    "# queues that control data flow from files\n",
    "num_epochs = 100\n",
    "batch_size=64\n",
    "capacity=1000\n",
    "min_after_dequeue=100\n",
    "lstm_units = 32\n",
    "lstm_layers = 2\n",
    "\n",
    "# this queue is taking all the files and asynchronously\n",
    "# passes them forward (so that the rest of the computational\n",
    "# graph that actually does computation doesn't have to wait for new input)\n",
    "file_queue = tf.train.string_input_producer(\n",
    "    tf.convert_to_tensor(base_names),\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True # not sure if this shuffle works\n",
    ")\n",
    "\n",
    "# the parsing that Al Quraishi provides to load the ProteinNet data\n",
    "res = read_protein(file_queue, max_length=1000)\n",
    "# unpacking the result\n",
    "id_, one_hot_primary, evolutionary, secondary, tertiary, ter_mask, pri_length, keep = res\n",
    "\n",
    "## I couldn't make shuffle batch work\n",
    "## because it doesn't have the dynamic padding included\n",
    "## workaround: https://github.com/tensorflow/tensorflow/issues/5147#issuecomment-271086206\n",
    "# ids, data, length = tf.train.shuffle_batch(\n",
    "#       [id_, one_hot_primary, pri_length], \n",
    "#       batch_size=batch_size, \n",
    "#       capacity=capacity,\n",
    "#       min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "# dynamic pad makes sure that the length of the proteins\n",
    "# is padded to the longest protein in the batch\n",
    "ids, one_hot_primary, evolutionary, labels, labels_mask, length = tf.train.batch(\n",
    "      [id_, one_hot_primary, evolutionary, tertiary, ter_mask, pri_length], \n",
    "      batch_size=batch_size, \n",
    "      capacity=capacity, \n",
    "      dynamic_pad=True\n",
    "    )\n",
    "\n",
    "# need the lengths to calculate the torsional angles\n",
    "protein_length = tf.gather(tf.shape(one_hot_primary), 1)\n",
    "protein_euc_length = tf.gather(tf.shape(labels), 1)\n",
    "\n",
    "# conver euclidean coordinates to dihedral angles\n",
    "dihedral_angles = dihedral_pipeline(labels, batch_size, protein_length)\n",
    "\n",
    "# prepare input data and setup the LSTM\n",
    "input_data = tf.concat([one_hot_primary, evolutionary], axis=2)\n",
    "outputs_conc = bidirectional_lstm(input_data=input_data, num_layers=lstm_layers, \n",
    "                                  rnn_size = lstm_units, keep_prob=0.05, lengths=length)\n",
    "\n",
    "# squeezing the output into tanh with 3 outputs\n",
    "pred = tf.layers.dense(outputs_conc, 3, activation=tf.nn.tanh, use_bias=False)\n",
    "# rescaling the output to match the scale of the angles (-180, 180)\n",
    "pred = tf.multiply(pred, tf.constant(180.))\n",
    "\n",
    "# choose a loss (mse or mae)\n",
    "loss = tf.losses.mean_squared_error(labels=dihedral_angles, predictions=pred)\n",
    "\n",
    "# learning rate placeholder for adaptive learning rate\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "# choose an optimizer to minimize the loss\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss, global_step=global_step)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 4855.8496\n",
      "Avg loss: 4844.3076\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the main training loop.\n",
    "\n",
    "The coord calls and try, exceptm, finally instructions are due to the way Queues operate.\n",
    "They use a coordinator and queue_runners to load the data asynchronously to the actual computations.\n",
    "\"\"\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # important to call both of these, because \n",
    "    # otherwise can't specify num_epochs in string_input_producer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()  \n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "    try:\n",
    "        # we can't access information from the queue\n",
    "        # to know when an epoch ends, so we define our\n",
    "        # own step counter and calculate an average loss every n steps\n",
    "        step = 0\n",
    "        \n",
    "        losses = []\n",
    "        avg_losses = []\n",
    "        \n",
    "        feed_learning_rate = init_learning_rate\n",
    "        while not coord.should_stop():        \n",
    "                \n",
    "            dihedral_angles_, labels_, pred_, loss_ = sess.run([dihedral_angles, labels, pred, loss], \n",
    "                                                               feed_dict={learning_rate: feed_learning_rate})\n",
    "\n",
    "            losses.append(loss_)\n",
    "            if step % 50 == 0:\n",
    "                avg_loss =  np.mean(losses)\n",
    "                avg_losses.append(avg_loss)\n",
    "                print(\"Avg loss:\", avg_loss)\n",
    "\n",
    "                losses = []\n",
    "                \n",
    "            if step * batch_size > training_samples:\n",
    "                print(\"EPOCH\")\n",
    "            \n",
    "            step += 1\n",
    "\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the avg losses over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get just the dihedral angles to see if they resemble how a ramachadran plot should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()  \n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "    \n",
    "    dihedral_angles_ = sess.run([dihedral_angles])\n",
    "    coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array(dihedral_angles_)[0,:,:,0]\n",
    "beta = np.array(dihedral_angles_)[0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x272034e50f0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGDdJREFUeJzt3XuMXGd5x/HfD+cCRElwapMsvgetEbbbWvXgBBUsKrbF\noKQmrQCD1EQixUUEsKqiNiGKGtWKRIkoStoCNSEiqUSiqCghhGArjgT5p0nYbU18Ib7kYrLWJnYS\nE0MTjOM8/WPO2LPrmd3ZnXPmXOb7kUZ75p0zM4/PHJ/nvJfzHkeEAAD97U15BwAAyB/JAABAMgAA\nkAwAACIZAABEMgAAiGQAABDJAAAgkgEAQNIZeQfQqTlz5sTixYvzDgMASmVkZOTFiJg71XqlSQaL\nFy/W8PBw3mEAQKnYPtDJejQTAQBIBgAAkgEAQCQDAIBIBgAAkQwAACIZAABEMkAXRg4c0ZXfeUwj\nB47kHQqALpEMMGO3bNurR/a9qFu27c07FABdKs0VyCiejUNLx/0FUF4kA8zYqkWzdefVl+QdBoAU\n0EyElugPAPoLyQAtD/z0BwD9hWRQUmmeubc68G8cWqo1g3PoDwD6BH0GJdU4gEvqut2+VUcw/QFA\nfyEZlFSaI3k48AOgmaikGgfwVYtmT+t93TQv0akMVBfJoM900zFMpzJQXTQT9Zlumpe4yAyoLkdE\n9x9i3y7pMkmHImJFUnajpM9IOpys9uWIeDB57TpJV0s6IemLEbF1qu+o1WrBPZABYHpsj0REbar1\n0mom+q6ktS3Kvx4RK5NHIxEsk7Re0vLkPd+wPSulOJAD+hKA8kslGUTEI5Je7nD1dZLujohjEfGM\npP2SVqcRRyscqLK36Ye79Mi+F7Xph7vyDgXADGXdgfwF20/Yvt12Y9jLPEnPNa0zmpSdxvYG28O2\nhw8fPtxqlSnR6dkD9vi/AEony2TwTUkXS1opaUzS16b7ARGxOSJqEVGbO3fujILgStrs3XDZMq0Z\nnKMbLluWdygAZiiz0UQR8UJj2fa3JT2QPD0oaUHTqvOTskxwQRUATC2zmoHtgaanV0jamSzfL2m9\n7bNtL5E0KOnxrOJA9miKA8ovlZqB7bskfUDSHNujkv5R0gdsr5QUkp6V9DeSFBG7bN8jabek1yVd\nExEn0ogD+Vi7YkA7Dr6itSsGpl4ZQCGlkgwi4pMtir8zyfo3Sbopje9G/rbsHNORV49ry84xfeqS\nhXmHA2AGmI4CXWvXSc+wXqA8SAboWrtJ8zrtSyBpAPkjGaBr7Q7mnQ7rpQMayB/JoELyOsNudzDv\ndJptrgUpBmpo/Y1kUCF5nWF3ezCfmDQ4KOWDGlp/YwrrCslrium0L+xL85ae6BxTlPe3VKaw7gWm\nsO4fIweO6JZte7VxaOm07+QGYLxeT2GNgqhCE8tMb+kJYOZIBhVDuy+AmaDPoGJo9wUwEySDimGW\nVgAzQTMRAIBkAAAgGQAARDIAAIhkAAAQyQAAIJIBAEAkAwCAUkoGtm+3fcj2zqayC2w/ZHtf8nd2\n02vX2d5ve4/tD6URQ69VYQ4gAGhIq2bwXUlrJ5RdK+nhiBiU9HDyXLaXSVovaXnynm/YnpVSHD3D\nHECnkBiB8kslGUTEI5JenlC8TtIdyfIdkj7aVH53RByLiGck7Ze0Oo04eom7c51CYgTKL8s+gwsj\nYixZfl7ShcnyPEnPNa03mpSdxvYG28O2hw8fPpx6gN2c0aY1zXIVzqpJjED59aQDOep30Jn2XXQi\nYnNE1CKiNnfu3NTjKsIZbRFi6Bb3HwDKL8tZS1+wPRARY7YHJB1Kyg9KWtC03vykrOeKMN1zEWIA\ngCxrBvdLuipZvkrSD5rK19s+2/YSSYOSHs8wjraKcEabdgxVaHYC0HtpDS29S9J/S3qX7VHbV0v6\niqQ/tb1P0lDyXBGxS9I9knZL2iLpmog4kUYcqEazU6dIfKiqPPbtVJqJIuKTbV76YJv1b5J0Uxrf\njfG6bXYq083oG4lPEjf0QaXksW9zp7OK6fZOZ2U6wNLfgqrKY992faBP8dVqtRgeHs47jMrLomYw\nk88sUw0FKDLbIxFRm2o95ibCOFl0qs+kH6Pxnr++42f0CQA9QDJA5mZyUdrGoaWa/dYzdeTV433R\nGQ7kjWSAzM2ktrFq0WzddtV7WiYRRhEB6aMDGYXVrjO8TJ3cQFlQM2iBM89iYy4kIH3UDFrgzLPY\nuh0+C+B0JIMWGL8OoN/QTNRCEeYsSgPNXQA6RTKosH6apwjVw8lMb5EMVN2djo5WlBknM71Fn4Gq\n22Fc9I5WppzAZOi76y2Sgdjp8lLVJIx0FP1kpmpIBmKnywtJGCgOkgFyQxIGioMOZAAAyQAAQDIo\njKoObwVQDpknA9vP2t5he7vt4aTsAtsP2d6X/O37cYWMqQaQp17VDP4kIlY23XrtWkkPR8SgpIeT\n532NC8QA5Cmv0UTrJH0gWb5D0k8k/UNOsRQCI2sA5KkXNYOQtM32iO0NSdmFETGWLD8v6cJWb7S9\nwfaw7eHDhw/3INTqo2+iGvgdkbZeJIP3RcRKSR+WdI3tNc0vRkSonjBOExGbI6IWEbW5c+f2INTq\no2+iGvgdkbbMm4ki4mDy95DteyWtlvSC7YGIGLM9IOlQ1nGgjqt+q4HfEWlz/cQ8ow+3z5H0poj4\ndbL8kKR/kvRBSS9FxFdsXyvpgoj4+8k+q1arxfDwcGaxAkAV2R5pGrzTVtY1gwsl3Wu78V3fi4gt\ntn8m6R7bV0s6IOnjGccBAJhEpn0GEfF0RPxh8lgeETcl5S9FxAcjYjAihiLi5SzjQD7o5OwNtjPS\nwBXIyAydnL3BdkYamLUUmaGTszfYzkhDph3IaUqrA5m7awEoizSOV512IPddMxFV6uqgrRxV18vj\nVd81E1GlLpfJzoy4bSaqrpfHq75LBswBVC6THfBJ7Ki6Xh6v+i4ZdIs+h96a7IBPYgfSQzKYJpom\neosDPtAbfdeB3C3uO5AeOoCB4qBmME2cqaaHWhZQHCQD5IYOYKA4SAbIDbUsoDjoMwAAkAwAACQD\nAIBIBpli6CSAsiAZZIhJ8QCUBaOJMsTQSQBlQTLIEEMnAZRFbs1Ettfa3mN7v+1r84oDAJBTMrA9\nS9K/S/qwpGWSPml7WR6xAADyqxmslrQ/Ip6OiN9JulvSupxiQaJIo5+mG0uesRdpuwEzlVcymCfp\nuabno0nZOLY32B62PXz48OGeBdevijT6abqx5Bl7kbYbMFOF7kCOiM2SNktSrVaLnMOpvLUrBrTj\n4Ctau2Ig71CmPRIrz5FbjBpDFeSVDA5KWtD0fH5Shhxt2TmmI68e15adY/rUJQtzjWW6I7HyHLnF\nqDFUQV7J4GeSBm0vUT0JrJf0qZxiQYIzXKB/5ZIMIuJ125+XtFXSLEm3R8SuPGLBKZzhAv0rtz6D\niHhQ0oN5fT8A4BTmJsI4DJME+hPJAONkPUySZDNzbDtkiWSAk0YOHNHR145r5YK3ZdaJzJj8mWPb\nIUuFvs4AvXXLtr3aPvqK1gzO0apFszP5DkYszRzbDllyRDmu5arVajE8PJx3GJU2cuCIbtm2VxuH\nlmaWDAD0lu2RiKhNtR41A5zE0FKgf9FngGmhExOoJpIBpoVOTKCaSAaYlo1DS7VmcM64Tszm2kKr\nmgO1CaD46DMooCJ35LbqV2jUFhoay431Gq//7y+P6KLz36JzzpqlGy5fXrh/G9DPqBkUUJGaYjo5\nq2+uLUysOTSuXTj37DP062MntO/Qb7R99JWO/m3UKIDeoWZQQHmOJx85cESbHtgtReiGy5ePO+tv\nN9KoUVtoVaNpXLuwcv75kqT/+90JnXPWrI7+bZ18N4B0VD4ZFLnJpZ08h3jesm2vtj/3K0nSpgd2\n64bL6remnunBuzmxTXf7c5EV0DuVbyYqUpNLGWwcWqpzz55VfzLNCxI3Di3Vyvnn6+hvXz/ZtNNI\nbK0SQaMZ6HuP/bJlc9Bk7wWQrsong1ajX9DeqkWz9d1PX6I1g3PGNRNNlUwbzUtPHf6Ntj/3K92y\nbe+Ubf6Nz75565PTStj0JQDpq3wzEVfVTl/zNmvVVNO2byBpXjr37HqfQONgv+PgK7rtqvecdobf\n+My1Kwa0ZedYxwmbvgQgfZWvGaA7zYmhcTbeqrZQb16qn1u88+3natWi2do4tFSz33qmjrx6vOVZ\nf2OdLTvHtHbFwMnaxFSo7QHpIxmgI80JoNXBuN68tLrevJR0Oq9aNFu3XfWeSQ/cUzUVtWoSaiSR\nTpMHgKkxayk6kuaorObPkuoJobmpqPnzr/zOY3pk34taMzhnXJNQu3IA4+U+a6ntGyV9RtLhpOjL\nyX2PZfs6SVdLOiHpixGxNas4kI7m5qKJ1yI0H7w7SRqbfrhL20df0dHXjuu+z7/v5Od+6pKFp63b\nbngpw06BdGXdTPT1iFiZPBqJYJmk9ZKWS1or6Ru2Z2Ucx2kYkTK5ybZPo7O41ZXEHY0+ssf/nUS7\n4aUMOwXSlUefwTpJd0fEsYh4RtJ+Sat7HQTXH0xusu2zcWipVi54m1bOP18bh5aOSxztOneb17nh\nsmUnr0gmGQPFkPXQ0i/YvlLSsKS/i4gjkuZJerRpndGk7DS2N0jaIEkLF57ehNANmhkmN3H7TGz+\nue+aPz65bqP9XqoP9WzVhj9xmOl5bzlTj+x7sd7cJLVscgLQO13VDGxvs72zxWOdpG9KuljSSklj\nkr423c+PiM0RUYuI2ty5c7sJ9TQ0M0xu4vaZqqYw1VDPicNMG+9RRNsmp4mmmiobwMx1VTOIiKFO\n1rP9bUkPJE8PSlrQ9PL8pAwFNllNqpML+xrDTDc9sFtHXzsuSScnt2t0Rk+shUwcYTTVVNkAZi7L\n0UQDETGWPL1C0s5k+X5J37P9L5LeIWlQ0uNZxYHpazUiKI0ruVctmq3z3nzGyRpGo+bx8doC3bz1\nSe15/tfjDvo7Dr6iI68e19Hfvq7z3nyG1q4YkDQ+IdHMB6Qjyw7kr9reYfsJSX8i6W8lKSJ2SbpH\n0m5JWyRdExEnMowDE3Q6Z1AWneutmpRu3vqkjrx6XDdvfVJSfXqK2W89U5+oLTjZlNS4MK2RoCY2\nY9FsBHQns2QQEX8VEb8fEX8QEX/eVEtQRNwUEe+MiHdFxI+ziqGquj3wTXWwz3K6h1Z9NZ+oLdAZ\nb7I+Uau3Hm7ZOaYjrx7X7rGjuvPqS3TD5cvbTmvR2BabHtjN6DCgC0xHUULdnrlPdbDvdef67rGj\nev2N0O6xoy3jm2xai5P9CBHMV9Qj1MKqqfKzllZRt8NiizSTa+O2mCsXvG3cwb/T+Lq5eQ4m1+5q\ncmaNrSZqBiWU97DYNM8MG7fFbCxPtx8j721RZe22ObPGVhM1gx4p4+0320njzLB5+KgkHX3t+KSf\nOVltqErbtkjabfMi1SyRHpJBj1Spap3G1dsTt8fEmUwnmuwAVKVtWyQc9PsLyaBHqjT9RRoHiYnb\no5vPrNK2BfLC/QyACkijqYzmtuJJ4zfp9H4GdCADFZDGhYLM5Fs8vfxNaCYCKiCNpjKa24qnl78J\nzUQFVvRqe9HjA0AzUSUUvdpe9PgAdI5mogLLs9reyVk/zQpAddBMhJYady9bMziHseZAiXXaTETN\nAC1x1g/0F5IBWuLqU6C/0IEMACAZAEXFfQP6W69/f5IBUFAM3e1vvf79u0oGtj9me5ftN2zXJrx2\nne39tvfY/lBT+ark3sj7bd9q293EAFQV9w3ob73+/bsaWmr73ZLekPQfkr4UEcNJ+TJJd0laLekd\nkrZJWhoRJ2w/LumLkh6T9KCkWzu5DzJDSwFg+npyBXJE/CIi9rR4aZ2kuyPiWEQ8I2m/pNW2BySd\nFxGPRj0L3Snpo93EAADoXlZ9BvMkPdf0fDQpm5csTywHAORoyusMbG+TdFGLl66PiB+kH9K4794g\naYMkLVy4MMuvAoC+NmUyiIihGXzuQUkLmp7PT8oOJssTy9t992ZJm6V6n8EM4gAAdCCrZqL7Ja23\nfbbtJZIGJT0eEWOSjtq+NBlFdKWkTGsXAICpdTu09Arbo5LeK+lHtrdKUkTsknSPpN2Stki6JiJO\nJG/7nKTbVO9UfkrSlCOJAADZYtZSAKgwbm4DAOgYyQC5Yv4doBhIBsgV8+8AxcD9DJArbqIDFAPJ\nALniJjpAMdBMBAAgGQAASAYAAJEMAAAiGQAARDIAAIhkAAAQyQAAoD5OBsyJAwCn9G0yYE4cADil\nb6ejYE4cADilb5MBc+IAwCl920wEADiFZAAA6C4Z2P6Y7V2237BdaypfbPs129uTx7eaXltle4ft\n/bZvte1uYgAAdK/bmsFOSX8h6ZEWrz0VESuTx2ebyr8p6TOSBpPH2i5jAAB0qatkEBG/iIg9na5v\ne0DSeRHxaESEpDslfbSbGAAA3cuyz2BJ0kT0U9vvT8rmSRptWmc0KasELmQDUFZTDi21vU3SRS1e\nuj4iftDmbWOSFkbES7ZXSbrP9vLpBmd7g6QNkrRw4cLpvr3nGheySWLYKoBSmTIZRMTQdD80Io5J\nOpYsj9h+StJSSQclzW9adX5S1u5zNkvaLEm1Wi2mG0evcSEbgLLK5KIz23MlvRwRJ2xfrHpH8dMR\n8bLto7YvlfSYpCsl/WsWMeSBC9kAlFW3Q0uvsD0q6b2SfmR7a/LSGklP2N4u6b8kfTYiXk5e+5yk\n2yTtl/SUpB93EwN6i34RoJq6qhlExL2S7m1R/n1J32/znmFJK7r5XuSHfhGgmvp2biLMDP0iQDWR\nDDAt9IsA1cTcRAAAkgEAgGQAABDJoG8wJBTAZEgGJdLNAZ17PgOYDMmgRLo5oG8cWqo1g3MKNySU\nGgtQDAwtLZFuxvgXdUgoF7EBxUAyKJGiHtC7wUVs+Ro5cES3bNurjUNLtWrR7LzDQY5oJioRmlSQ\ntqmaHme6z7Gvlg/JoESq2AlcxX9TmUzVlzTT34fftXxoJiqRKjapVPHfVCZTNT3O9Pfhdy0f129F\nXHy1Wi2Gh4fzDgMASsX2SETUplqPZiIAAMkAAEAyAACIZAAAEMkAACCSAQBAJAMAgEp0nYHtw5IO\n5B3HJOZIejHvIDpQljglYs1CWeKUiDUtiyJi7lQrlSYZFJ3t4U4u7MhbWeKUiDULZYlTItZeo5kI\nAEAyAACQDNK0Oe8AOlSWOCVizUJZ4pSItafoMwAAUDMAAJAMps32x2zvsv2G7VpT+WLbr9nenjy+\n1fTaKts7bO+3fatt5xlr8tp1STx7bH8o71gnxHaj7YNN2/IjU8WdF9trk1j2274273gmsv1s8ntu\ntz2clF1g+yHb+5K/udzv0vbttg/Z3tlU1ja2vH77NnGWZh/tWETwmMZD0rslvUvSTyTVmsoXS9rZ\n5j2PS7pUkiX9WNKHc451maSfSzpb0hJJT0malWesE+K+UdKXWpS3jTunfWFWEsPFks5KYluW5/7Z\nIsZnJc2ZUPZVSdcmy9dK+uecYlsj6Y+a/9+0iy3P375NnKXYR6fzoGYwTRHxi4jY0+n6tgcknRcR\nj0Z9b7lT0kczC7DJJLGuk3R3RByLiGck7Ze0Os9YO9Qy7hzjWS1pf0Q8HRG/k3R3EmPRrZN0R7J8\nh3L6jSPiEUkvTyhuF1tuv32bONsp2j7aMZJBupYkVcaf2n5/UjZP0mjTOqNJWZ7mSXqu6XkjpiLF\n+gXbTyRV9EZTQbu481K0eFoJSdtsj9jekJRdGBFjyfLzki7MJ7SW2sVWxG1dhn20Y9wDuQXb2yRd\n1OKl6yPiB23eNiZpYUS8ZHuVpPtsL88syMQMY83dZHFL+qakTaofyDZJ+pqkT/cuukp5X0QctP12\nSQ/ZfrL5xYgI24UcUljk2FTBfZRk0EJEDM3gPcckHUuWR2w/JWmppIOS5jetOj8pS8VMYk2+f0HT\n80ZMmcbarNO4bX9b0gPJ03Zx56Vo8ZwmIg4mfw/Zvlf1JosXbA9ExFjSNHgo1yDHaxdbobZ1RLzQ\nWC74PtoxmolSYnuu7VnJ8sWSBiU9nVR5j9q+NBmZc6WkvM/Y75e03vbZtpeoHuvjRYk1OQg0XCGp\nMYqjZdy9jq/JzyQN2l5i+yxJ65MYC8H2ObbPbSxL+jPVt+X9kq5KVrtK+e+PzdrFVqjfvkT7aOfy\n7sEu20P1H35U9VrAC5K2JuV/KWmXpO2S/kfS5U3vqam+szwl6d+UXOyXV6zJa9cn8exR04ihvGKd\nEPd/Stoh6QnV/3MNTBV3jvvDRyTtTWK6Pu94JsR2seojW36e7JvXJ+W/J+lhSfskbZN0QU7x3aV6\n8+rxZD+9erLY8vrt28RZmn200wdXIAMAaCYCAJAMAAAiGQAARDIAAIhkAAAQyQAAIJIBAEAkAwCA\npP8H3PCRiADg4UkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2720394f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(beta[3], alpha[3], s=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
