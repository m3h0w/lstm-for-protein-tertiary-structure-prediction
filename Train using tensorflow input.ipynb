{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "NUM_DIMENSIONS = 3\n",
    "NUM_DIHEDRALS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drmsd(u, v, weights, name=None):\n",
    "    \"\"\" Computes the dRMSD of two tensors of vectors.\n",
    "        Vectors are assumed to be in the third dimension. Op is done element-wise over batch.\n",
    "    Args:\n",
    "        u, v:    [NUM_STEPS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "        weights: [NUM_STEPS, NUM_STEPS, BATCH_SIZE]\n",
    "    Returns:\n",
    "                 [BATCH_SIZE]\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'dRMSD', [u, v, weights]) as scope:\n",
    "        u = tf.convert_to_tensor(u, name='u')\n",
    "        v = tf.convert_to_tensor(v, name='v')\n",
    "        weights = tf.convert_to_tensor(weights, name='weights')\n",
    "\n",
    "        diffs = pairwise_distance(u) - pairwise_distance(v)                                  # [NUM_STEPS, NUM_STEPS, BATCH_SIZE]\n",
    "        norms = reduce_l2_norm(diffs, reduction_indices=[0, 1], weights=weights, name=scope) # [BATCH_SIZE]\n",
    "\n",
    "        return norms\n",
    "\n",
    "def pairwise_distance(u, name=None):\n",
    "    \"\"\" Computes the pairwise distance (l2 norm) between all vectors in the tensor.\n",
    "        Vectors are assumed to be in the third dimension. Op is done element-wise over batch.\n",
    "    Args:\n",
    "        u: [NUM_STEPS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "    Returns:\n",
    "           [NUM_STEPS, NUM_STEPS, BATCH_SIZE]\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'pairwise_distance', [u]) as scope:\n",
    "        u = tf.convert_to_tensor(u, name='u')\n",
    "        \n",
    "        diffs = u - tf.expand_dims(u, 1)                                 # [NUM_STEPS, NUM_STEPS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "        norms = reduce_l2_norm(diffs, reduction_indices=[3], name=scope) # [NUM_STEPS, NUM_STEPS, BATCH_SIZE]\n",
    "\n",
    "        return norms\n",
    "\n",
    "def point_to_coordinate(pt, num_fragments=6, parallel_iterations=4, swap_memory=False, name=None):\n",
    "    \"\"\" Takes points from dihedral_to_point and sequentially converts them into the coordinates of a 3D structure.\n",
    "        Reconstruction is done in parallel, by independently reconstructing num_fragments fragments and then \n",
    "        reconstituting the chain at the end in reverse order. The core reconstruction algorithm is NeRF, based on \n",
    "        DOI: 10.1002/jcc.20237 by Parsons et al. 2005. The parallelized version is described in XXX.\n",
    "    Args:\n",
    "        pt: [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "    Opts:\n",
    "        num_fragments: Number of fragments to reconstruct in parallel. If None, the number is chosen adaptively\n",
    "    Returns:\n",
    "            [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS] \n",
    "    \"\"\"                             \n",
    "\n",
    "    with tf.name_scope(name, 'point_to_coordinate', [pt]) as scope:\n",
    "        pt = tf.convert_to_tensor(pt, name='pt')\n",
    "\n",
    "        # compute optimal number of fragments if needed\n",
    "        s = tf.shape(pt)[0] # NUM_STEPS x NUM_DIHEDRALS\n",
    "        if num_fragments is None: num_fragments = tf.cast(tf.sqrt(tf.cast(s, dtype=tf.float32)), dtype=tf.int32)\n",
    "\n",
    "        # initial three coordinates (specifically chosen to eliminate need for extraneous matmul)\n",
    "        Triplet = collections.namedtuple('Triplet', 'a, b, c')\n",
    "        batch_size = pt.get_shape().as_list()[1] # BATCH_SIZE\n",
    "        init_mat = np.array([[-np.sqrt(1.0 / 2.0), np.sqrt(3.0 / 2.0), 0], [-np.sqrt(2.0), 0, 0], [0, 0, 0]], dtype='float32')\n",
    "        init_coords = Triplet(*[tf.reshape(tf.tile(row[np.newaxis], tf.stack([num_fragments * batch_size, 1])), \n",
    "                                           [num_fragments, batch_size, NUM_DIMENSIONS]) for row in init_mat])\n",
    "                      # NUM_DIHEDRALS x [NUM_FRAGS, BATCH_SIZE, NUM_DIMENSIONS] \n",
    "        \n",
    "        # pad points to yield equal-sized fragments\n",
    "        r = ((num_fragments - (s % num_fragments)) % num_fragments)          # (NUM_FRAGS x FRAG_SIZE) - (NUM_STEPS x NUM_DIHEDRALS)\n",
    "        pt = tf.pad(pt, [[0, r], [0, 0], [0, 0]])                            # [NUM_FRAGS x FRAG_SIZE, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "        pt = tf.reshape(pt, [num_fragments, -1, batch_size, NUM_DIMENSIONS]) # [NUM_FRAGS, FRAG_SIZE,  BATCH_SIZE, NUM_DIMENSIONS]\n",
    "        pt = tf.transpose(pt, perm=[1, 0, 2, 3])                             # [FRAG_SIZE, NUM_FRAGS,  BATCH_SIZE, NUM_DIMENSIONS]\n",
    "\n",
    "        # extension function used for single atom reconstruction and whole fragment alignment\n",
    "        def extend(tri, pt, multi_m):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tri: NUM_DIHEDRALS x [NUM_FRAGS/0,         BATCH_SIZE, NUM_DIMENSIONS]\n",
    "                pt:                  [NUM_FRAGS/FRAG_SIZE, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "                multi_m: bool indicating whether m (and tri) is higher rank. pt is always higher rank; what changes is what the first rank is.\n",
    "            \"\"\"\n",
    "\n",
    "            bc = tf.nn.l2_normalize(tri.c - tri.b, -1, name='bc')                                        # [NUM_FRAGS/0, BATCH_SIZE, NUM_DIMS]        \n",
    "            n = tf.nn.l2_normalize(tf.cross(tri.b - tri.a, bc), -1, name='n')                            # [NUM_FRAGS/0, BATCH_SIZE, NUM_DIMS]\n",
    "            if multi_m: # multiple fragments, one atom at a time. \n",
    "                m = tf.transpose(tf.stack([bc, tf.cross(n, bc), n]), perm=[1, 2, 3, 0], name='m')        # [NUM_FRAGS,   BATCH_SIZE, NUM_DIMS, 3 TRANS]\n",
    "            else: # single fragment, reconstructed entirely at once.\n",
    "                s = tf.pad(tf.shape(pt), [[0, 1]], constant_values=3)                                    # FRAG_SIZE, BATCH_SIZE, NUM_DIMS, 3 TRANS\n",
    "                m = tf.transpose(tf.stack([bc, tf.cross(n, bc), n]), perm=[1, 2, 0])                     # [BATCH_SIZE, NUM_DIMS, 3 TRANS]\n",
    "                m = tf.reshape(tf.tile(m, [s[0], 1, 1]), s, name='m')                                    # [FRAG_SIZE, BATCH_SIZE, NUM_DIMS, 3 TRANS]\n",
    "            coord = tf.add(tf.squeeze(tf.matmul(m, tf.expand_dims(pt, 3)), axis=3), tri.c, name='coord') # [NUM_FRAGS/FRAG_SIZE, BATCH_SIZE, NUM_DIMS]\n",
    "            return coord\n",
    "        \n",
    "        # loop over FRAG_SIZE in NUM_FRAGS parallel fragments, sequentially generating the coordinates for each fragment across all batches\n",
    "        i = tf.constant(0)\n",
    "        s_padded = tf.shape(pt)[0] # FRAG_SIZE\n",
    "        coords_ta = tf.TensorArray(tf.float32, size=s_padded, tensor_array_name='coordinates_array')\n",
    "                    # FRAG_SIZE x [NUM_FRAGS, BATCH_SIZE, NUM_DIMENSIONS] \n",
    "        \n",
    "        def loop_extend(i, tri, coords_ta): # FRAG_SIZE x [NUM_FRAGS, BATCH_SIZE, NUM_DIMENSIONS] \n",
    "            coord = extend(tri, pt[i], True)\n",
    "            return [i + 1, Triplet(tri.b, tri.c, coord), coords_ta.write(i, coord)]\n",
    "\n",
    "        _, tris, coords_pretrans_ta = tf.while_loop(lambda i, _1, _2: i < s_padded, loop_extend, [i, init_coords, coords_ta],\n",
    "                                                    parallel_iterations=parallel_iterations, swap_memory=swap_memory)\n",
    "                                      # NUM_DIHEDRALS x [NUM_FRAGS, BATCH_SIZE, NUM_DIMENSIONS], \n",
    "                                      # FRAG_SIZE x [NUM_FRAGS, BATCH_SIZE, NUM_DIMENSIONS] \n",
    "        \n",
    "        # loop over NUM_FRAGS in reverse order, bringing all the downstream fragments in alignment with current fragment\n",
    "        coords_pretrans = tf.transpose(coords_pretrans_ta.stack(), perm=[1, 0, 2, 3]) # [NUM_FRAGS, FRAG_SIZE, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "        i = tf.shape(coords_pretrans)[0] # NUM_FRAGS\n",
    "\n",
    "        def loop_trans(i, coords):\n",
    "            transformed_coords = extend(Triplet(*[di[i] for di in tris]), coords, False)\n",
    "            return [i - 1, tf.concat([coords_pretrans[i], transformed_coords], 0)]\n",
    "\n",
    "        _, coords_trans = tf.while_loop(lambda i, _: i > -1, loop_trans, [i - 2, coords_pretrans[-1]],\n",
    "                                        parallel_iterations=parallel_iterations, swap_memory=swap_memory)\n",
    "                          # [NUM_FRAGS x FRAG_SIZE, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "\n",
    "        # lose last atom and pad from the front to gain an atom ([0,0,0], consistent with init_mat), to maintain correct atom ordering\n",
    "        coords = tf.pad(coords_trans[:s-1], [[1, 0], [0, 0], [0, 0]], name=scope) # [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "\n",
    "        return coords\n",
    "    \n",
    "def dihedral_to_point(dihedral, r=BOND_LENGTHS, theta=BOND_ANGLES, name=None):\n",
    "    \"\"\" Takes triplets of dihedral angles (phi, psi, omega) and returns 3D points ready for use in\n",
    "        reconstruction of coordinates. Bond lengths and angles are based on idealized averages.\n",
    "    Args:\n",
    "        dihedral: [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "    Returns:\n",
    "                  [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'dihedral_to_point', [dihedral]) as scope:\n",
    "        dihedral = tf.convert_to_tensor(dihedral, name='dihedral') # [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "\n",
    "        num_steps  = tf.shape(dihedral)[0]\n",
    "        batch_size = dihedral.get_shape().as_list()[1] # important to use get_shape() to keep batch_size fixed for performance reasons\n",
    "\n",
    "        r_cos_theta = tf.constant(r * np.cos(np.pi - theta), name='r_cos_theta') # [NUM_DIHEDRALS]\n",
    "        r_sin_theta = tf.constant(r * np.sin(np.pi - theta), name='r_sin_theta') # [NUM_DIHEDRALS]\n",
    "\n",
    "        pt_x = tf.tile(tf.reshape(r_cos_theta, [1, 1, -1]), [num_steps, batch_size, 1], name='pt_x') # [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "        pt_y = tf.multiply(tf.cos(dihedral), r_sin_theta,                               name='pt_y') # [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "        pt_z = tf.multiply(tf.sin(dihedral), r_sin_theta,                               name='pt_z') # [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "\n",
    "        pt = tf.stack([pt_x, pt_y, pt_z])                                                       # [NUM_DIMS, NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\n",
    "        pt_perm = tf.transpose(pt, perm=[1, 3, 2, 0])                                           # [NUM_STEPS, NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMS]\n",
    "        pt_final = tf.reshape(pt_perm, [num_steps * NUM_DIHEDRALS, batch_size, NUM_DIMENSIONS], # [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMS]\n",
    "                              name=scope) \n",
    "\n",
    "        return pt_final\n",
    "    \n",
    "def _coordinates(dihedrals):\n",
    "    \"\"\" Converts dihedrals into full 3D structures. \"\"\"\n",
    "\n",
    "    # converts dihedrals to points ready for reconstruction.\n",
    "    points = dihedral_to_point(dihedrals) # [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "             \n",
    "    # converts points to final 3D coordinates.\n",
    "    coordinates = point_to_coordinate(points) \n",
    "                  # [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing provided by AlQuraishi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AAS = 20\n",
    "NUM_DIMENSIONS = 3\n",
    "\n",
    "def masking_matrix(mask, name=None):\n",
    "    \"\"\" Constructs a masking matrix to zero out pairwise distances due to missing residues or padding. \n",
    "\n",
    "    Args:\n",
    "        mask: 0/1 vector indicating whether a position should be masked (0) or not (1)\n",
    "\n",
    "    Returns:\n",
    "        A square matrix with all 1s except for rows and cols whose corresponding indices in mask are set to 0.\n",
    "        [MAX_SEQ_LENGTH, MAX_SEQ_LENGTH]\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'masking_matrix', [mask]) as scope:\n",
    "        mask = tf.convert_to_tensor(mask, name='mask')\n",
    "\n",
    "        mask = tf.expand_dims(mask, 0)\n",
    "        base = tf.ones([tf.size(mask), tf.size(mask)])\n",
    "        matrix_mask = base * mask * tf.transpose(mask)\n",
    "\n",
    "        return matrix_mask\n",
    "        \n",
    "def read_protein(filename_queue, max_length, num_evo_entries=21, name=None):\n",
    "    \"\"\" Reads and parses a ProteinNet TF Record. \n",
    "\n",
    "        Primary sequences are mapped onto 20-dimensional one-hot vectors.\n",
    "        Evolutionary sequences are mapped onto num_evo_entries-dimensional real-valued vectors.\n",
    "        Secondary structures are mapped onto ints indicating one of 8 class labels.\n",
    "        Tertiary coordinates are flattened so that there are 3 times as many coordinates as \n",
    "        residues.\n",
    "\n",
    "        Evolutionary, secondary, and tertiary entries are optional.\n",
    "\n",
    "    Args:\n",
    "        filename_queue: TF queue for reading files\n",
    "        max_length:     Maximum length of sequence (number of residues) [MAX_LENGTH]. Not a \n",
    "                        TF tensor and is thus a fixed value.\n",
    "\n",
    "    Returns:\n",
    "        id: string identifier of record\n",
    "        one_hot_primary: AA sequence as one-hot vectors\n",
    "        evolutionary: PSSM sequence as vectors\n",
    "        secondary: DSSP sequence as int class labels\n",
    "        tertiary: 3D coordinates of structure\n",
    "        matrix_mask: Masking matrix to zero out pairwise distances in the masked regions\n",
    "        pri_length: Length of amino acid sequence\n",
    "        keep: True if primary length is less than or equal to max_length\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope(name, 'read_protein', []) as scope:\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "        context, features = tf.parse_single_sequence_example(serialized_example,\n",
    "                                context_features={'id': tf.FixedLenFeature((1,), tf.string)},\n",
    "                                sequence_features={\n",
    "                                    'primary':      tf.FixedLenSequenceFeature((1,),               tf.int64),\n",
    "                                    'evolutionary': tf.FixedLenSequenceFeature((num_evo_entries,), tf.float32, allow_missing=True),\n",
    "                                    'secondary':    tf.FixedLenSequenceFeature((1,),               tf.int64,   allow_missing=True),\n",
    "                                    'tertiary':     tf.FixedLenSequenceFeature((NUM_DIMENSIONS,),  tf.float32, allow_missing=True),\n",
    "                                    'mask':         tf.FixedLenSequenceFeature((1,),               tf.float32, allow_missing=True)})\n",
    "        id_ = context['id'][0]\n",
    "        primary =   tf.to_int32(features['primary'][:, 0])\n",
    "        evolutionary =          features['evolutionary']\n",
    "        secondary = tf.to_int32(features['secondary'][:, 0])\n",
    "        tertiary =              features['tertiary']\n",
    "        mask =                  features['mask'][:, 0]\n",
    "\n",
    "        pri_length = tf.size(primary)\n",
    "        \n",
    "        keep = tf.ones_like(pri_length)\n",
    "        if max_length:\n",
    "            keep = pri_length <= max_length\n",
    "\n",
    "        one_hot_primary = tf.one_hot(primary, NUM_AAS)\n",
    "\n",
    "        # Generate tertiary masking matrix--if mask is missing then assume all residues are present\n",
    "        mask = tf.cond(tf.not_equal(tf.size(mask), 0), lambda: mask, lambda: tf.ones([pri_length]))\n",
    "        ter_mask = masking_matrix(mask, name='ter_mask')        \n",
    "\n",
    "        return id_, one_hot_primary, evolutionary, secondary, tertiary, ter_mask, pri_length, keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions of how to calculate dihedral angles and set up a bidirecitonal lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_rad2deg(rad):\n",
    "    pi_on_180 = 0.017453292519943295\n",
    "    return rad / pi_on_180\n",
    "\n",
    "# takes a 4-dimensional tensor (N, K, 4, 3) and outputs (N, K, 3) angles\n",
    "def dihedral_tf3(p):\n",
    "    p0 = tf.gather(p, 0, axis=2)\n",
    "    p1 = tf.gather(p, 1, axis=2)\n",
    "    p2 = tf.gather(p, 2, axis=2)\n",
    "    p3 = tf.gather(p, 3, axis=2)\n",
    "    \n",
    "    b0 = -1.0 * (tf.subtract(p1, p0))\n",
    "    b1 = tf.subtract(p2, p1)\n",
    "    b2 = tf.subtract(p3, p2)\n",
    "    \n",
    "    b1 = tf.divide(b1, tf.add(tf.norm(b1, axis=2, keepdims=True), tf.constant(1e-10)))\n",
    "#     b1 = tf.where(tf.is_nan(b1), tf.ones_like(b1), b1) # what to do when norm is 0?\n",
    "    \n",
    "    v = tf.subtract(b0, tf.einsum('bi,bij->bij', tf.einsum('bij,bij->bi', b0, b1), b1))\n",
    "    w = tf.subtract(b2, tf.einsum('bi,bij->bij', tf.einsum('bij,bij->bi', b2, b1), b1))\n",
    "    \n",
    "    x = tf.reduce_sum( tf.multiply( v, w ), 2, keepdims=True )\n",
    "    y = tf.reduce_sum( tf.multiply( tf.cross(b1, v), w ), 2, keepdims=True )\n",
    "\n",
    "#     return tf_rad2deg(tf.atan2(y,x))\n",
    "    return tf.atan2(y,x)\n",
    "\n",
    "# euclidean_coordinates are of shape (batch_size, protein_length, 3)\n",
    "def dihedral_pipeline(euclidean_coordinates, batch_size, protein_length):\n",
    "    # chooses all possible slices of length 4\n",
    "    euclidean_coordinates = euclidean_coordinates[:,:,:,None]\n",
    "    all_4_len_slices_euc_coord = tf.extract_image_patches(euclidean_coordinates,\n",
    "      ksizes=[1, 4, 3, 1],\n",
    "      strides=[1, 1, 1, 1],\n",
    "      rates=[1, 1, 1, 1],\n",
    "      padding='VALID')\n",
    "    all_4_len_slices_euc_coord = tf.reshape(tf.squeeze(all_4_len_slices_euc_coord), [batch_size, -1, 4, 3])\n",
    "\n",
    "    # calculates torsional angles on the entire batch\n",
    "    dihedral_angles = dihedral_tf3(all_4_len_slices_euc_coord)\n",
    "\n",
    "    # adds 3 zeros at the end because I can't calculate the angle of\n",
    "    # the last 3 atmos (need at least 4 atoms to calculate an angle)\n",
    "    padding = tf.constant([[0, 0], [0,3], [0,0]])\n",
    "    dihedral_angles = tf.pad(dihedral_angles, padding)\n",
    "\n",
    "    # reshaping the angles (because input is 3 times the length of normal protein)\n",
    "    dihedral_angles_shape = tf.gather(tf.shape(dihedral_angles), [0,1])\n",
    "    dihedral_angles = tf.reshape(dihedral_angles, shape=dihedral_angles_shape)\n",
    "    return tf.reshape(dihedral_angles, shape=(tf.gather(dihedral_angles_shape, 0), protein_length, 3))\n",
    "    \n",
    "# helper for setting up the bidirectional, multilayer lstm\n",
    "def bidirectional_lstm(input_data, num_layers, rnn_size, keep_prob, lengths):\n",
    "    output = input_data\n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer),reuse=tf.AUTO_REUSE):\n",
    "\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size, state_is_tuple = True)\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size, state_is_tuple = True)\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, input_keep_prob = keep_prob)\n",
    "\n",
    "            outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                              cell_bw, \n",
    "                                                              output,\n",
    "                                                              dtype=tf.float32,\n",
    "                                                              sequence_length=lengths)\n",
    "            output = tf.concat(outputs,2)\n",
    "\n",
    "    return output\n",
    "\n",
    "# helper to count number of records in a TF record file\n",
    "def get_num_records(tf_record_file):\n",
    "    return len([x for x in tf.python_io.tf_record_iterator(tf_record_file)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and load training paths. Count the number of training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../Data/ProteinNet/casp7/training/50/*']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13024"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose paths from which to get training data\n",
    "percentages = [30, 50, 70, 90]\n",
    "percentages = [50]\n",
    "main_path = \"../../Data/ProteinNet/casp7/training/\"\n",
    "paths = [main_path + str(perc) + '/*' for perc in percentages]\n",
    "print(paths)\n",
    "# load all the file names from these paths\n",
    "base_names = [glob.glob(a_path) for a_path in paths]\n",
    "base_names = list(np.concatenate(base_names))\n",
    "\n",
    "training_samples = np.sum([get_num_records(file) for file in base_names])\n",
    "training_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'multiples' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    921\u001b[0m           elems_as_tensors.append(\n\u001b[0;32m--> 922\u001b[0;31m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0m\u001b[1;32m    923\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 207\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    523\u001b[0m               observed = ops.internal_convert_to_tensor(\n\u001b[0;32m--> 524\u001b[0;31m                   values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    921\u001b[0m           elems_as_tensors.append(\n\u001b[0;32m--> 922\u001b[0;31m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0m\u001b[1;32m    923\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 207\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    208\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-322a50b34da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dihedral_angles\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdihedral_angles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mcoordinates_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedral_angles_deg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# prepare input data and setup the LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-bc875680f631>\u001b[0m in \u001b[0;36m_coordinates\u001b[0;34m(dihedrals)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# converts dihedrals to points ready for reconstruction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdihedral_to_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedrals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [NUM_STEPS x NUM_DIHEDRALS, BATCH_SIZE, NUM_DIMENSIONS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# converts points to final 3D coordinates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-bc875680f631>\u001b[0m in \u001b[0;36mdihedral_to_point\u001b[0;34m(dihedral, r, theta, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mr_sin_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r_sin_theta'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [NUM_DIHEDRALS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mpt_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_cos_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt_x'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mpt_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_sin_theta\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt_y'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mpt_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdihedral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_sin_theta\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt_z'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [NUM_STEPS, BATCH_SIZE, NUM_DIHEDRALS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m   8617\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8618\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 8619\u001b[0;31m         \"Tile\", input=input, multiples=multiples, name=name)\n\u001b[0m\u001b[1;32m   8620\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8621\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m               raise ValueError(\n\u001b[1;32m    527\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    529\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    530\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'multiples' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# the input pipeline should be rewritten using\n",
    "# the new dataset api that tesnorflow introduced\n",
    "\n",
    "# parameters for the training and\n",
    "# queues that control data flow from files\n",
    "num_epochs = 100\n",
    "batch_size=32\n",
    "capacity=1000\n",
    "min_after_dequeue=100\n",
    "lstm_units = 500\n",
    "lstm_layers = 2\n",
    "\n",
    "limit_protein_size = None\n",
    "\n",
    "# this queue is taking all the files and asynchronously\n",
    "# passes them forward (so that the rest of the computational\n",
    "# graph that actually does computation doesn't have to wait for new input)\n",
    "file_queue = tf.train.string_input_producer(\n",
    "    tf.convert_to_tensor(base_names),\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=True # not sure if this shuffle works\n",
    ")\n",
    "\n",
    "# the parsing that Al Quraishi provides to load the ProteinNet data\n",
    "res = read_protein(file_queue, max_length=limit_protein_size)\n",
    "# unpacking the result\n",
    "id_, one_hot_primary, evolutionary, secondary, tertiary, ter_mask, pri_length, keep = res\n",
    "\n",
    "## I couldn't make shuffle batch work\n",
    "## because it doesn't have the dynamic padding included\n",
    "## workaround: https://github.com/tensorflow/tensorflow/issues/5147#issuecomment-271086206\n",
    "# ids, data, length = tf.train.shuffle_batch(\n",
    "#       [id_, one_hot_primary, pri_length], \n",
    "#       batch_size=batch_size, \n",
    "#       capacity=capacity,\n",
    "#       min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "# dynamic pad makes sure that the length of the proteins\n",
    "# is padded to the longest protein in the batch\n",
    "ids, one_hot_primary, evolutionary, labels, labels_mask, length, keep = tf.train.batch(\n",
    "      [id_, one_hot_primary, evolutionary, tertiary, ter_mask, pri_length, keep], \n",
    "      batch_size=batch_size, \n",
    "      capacity=capacity, \n",
    "      dynamic_pad=True\n",
    "    )\n",
    "\n",
    "if limit_protein_size:\n",
    "    ids = tf.boolean_mask(ids, keep, axis=0)\n",
    "    one_hot_primary = tf.boolean_mask(one_hot_primary, keep, axis=0)\n",
    "    evolutionary = tf.boolean_mask(evolutionary, keep, axis=0)\n",
    "    labels = tf.boolean_mask(labels, keep, axis=0)\n",
    "    labels_mask = tf.boolean_mask(labels_mask, keep, axis=0)\n",
    "    length = tf.boolean_mask(length, keep, axis=0)\n",
    "\n",
    "# refresh the batch_size because the keep mask could have\n",
    "# made it smaller\n",
    "batch_size = tf.shape(one_hot_primary)[0]\n",
    "\n",
    "## bucketting by length might speed up the trianing \n",
    "## https://github.com/tensorflow/tensorflow/issues/2354\n",
    "# tf.contrib.training.bucket_by_sequence_length(\n",
    "#     input_length,\n",
    "#     tensors,\n",
    "#     batch_size,\n",
    "#     bucket_boundaries,\n",
    "#     num_threads=1,\n",
    "#     capacity=32,\n",
    "#     bucket_capacities=None,\n",
    "#     shapes=None,\n",
    "#     dynamic_pad=False,\n",
    "#     allow_smaller_final_batch=False,\n",
    "#     keep_input=True,\n",
    "#     shared_name=None,\n",
    "#     name=None\n",
    "# )\n",
    "\n",
    "# need the lengths to calculate the torsional angles\n",
    "protein_length = tf.gather(tf.shape(one_hot_primary), 1)\n",
    "protein_euc_length = tf.gather(tf.shape(labels), 1)\n",
    "\n",
    "# conver euclidean coordinates to dihedral angles\n",
    "dihedral_angles = dihedral_pipeline(labels, batch_size, protein_length)\n",
    "dih_x = tf.cos(dihedral_angles)\n",
    "dih_y = tf.sin(dihedral_angles)\n",
    "dihedral_angles_deg = tf_rad2deg(dihedral_angles)\n",
    "tf.summary.histogram(\"dihedral_angles\", dihedral_angles)\n",
    "\n",
    "coordinates_rec = _coordinates(tf.transpose(dihedral_angles, perm=[1,0,2]))\n",
    "\n",
    "# prepare input data and setup the LSTM\n",
    "input_data = tf.concat([one_hot_primary, evolutionary], axis=2)\n",
    "# outputs_conc = bidirectional_lstm(input_data=input_data, num_layers=lstm_layers, \n",
    "#                                   rnn_size = lstm_units, keep_prob=0.05, lengths=length)\n",
    "\n",
    "# cells_fw = []\n",
    "# cells_bw = []\n",
    "# for _ in range(lstm_layers):\n",
    "#     cells_fw.append(tf.contrib.rnn.LSTMCell(lstm_units, state_is_tuple = True))\n",
    "#     cells_bw.append(tf.contrib.rnn.LSTMCell(lstm_units, state_is_tuple = True))\n",
    "    \n",
    "# outputs_conc, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "#     cells_fw=cells_fw,\n",
    "#     cells_bw=cells_bw,\n",
    "#     inputs = input_data,\n",
    "#     initial_states_fw=None,\n",
    "#     initial_states_bw=None,\n",
    "#     dtype=tf.float32,\n",
    "#     sequence_length=length,\n",
    "#     scope=None\n",
    "# )\n",
    "gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
    "    1, lstm_units,\n",
    "    kernel_initializer=tf.orthogonal_initializer())\n",
    "outputs_conc, _ = gru(tf.transpose(input_data, (1, 0, 2)))\n",
    "outputs_conc = tf.where(tf.is_nan(outputs_conc), tf.add(tf.zeros_like(outputs_conc), tf.constant(0.)), outputs_conc)\n",
    "tf.summary.histogram(\"input_data\", input_data)\n",
    "tf.summary.histogram(\"outputs_conc\", outputs_conc)\n",
    "\n",
    "# # squeezing the output into tanh with 3 outputs\n",
    "# pred_angles = tf.layers.dense(outputs_conc, 3, activation=tf.nn.tanh, use_bias=False)\n",
    "# # rescaling the output to match the scale of the angles (-180, 180)\n",
    "# pred_angles = tf.multiply(pred_angles, tf.constant(np.pi))\n",
    "# angle_loss = tf.losses.absolute_difference(labels=tf.squeeze(dihedral_angles), predictions=tf.squeeze(pred_angles))\n",
    "\n",
    "# squeezing the output into tanh with 6 outputs to represent the angles as\n",
    "# points on a plane\n",
    "# pred = tf.layers.dense(outputs_conc, 6, activation=tf.nn.tanh, use_bias=False, \n",
    "#                        kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.5))\n",
    "pred = tf.layers.dense(\n",
    "    tf.layers.batch_normalization(outputs_conc),\n",
    "    6, activation=tf.nn.tanh, \n",
    "    kernel_initializer=tf.orthogonal_initializer()\n",
    ")\n",
    "# pred = tf.subtract(pred, tf.constant(0.5))\n",
    "pred = tf.where(tf.is_nan(pred), tf.add(tf.zeros_like(pred), tf.constant(0.)), pred)\n",
    "tf.summary.histogram(\"pred\", pred)\n",
    "\n",
    "# x1, y1 = tf.gather(pred, 0, axis=2), tf.gather(pred, 1, axis=2)\n",
    "# x2, y2 = tf.gather(pred, 2, axis=2), tf.gather(pred, 3, axis=2)\n",
    "# x3, y3 = tf.gather(pred, 4, axis=2), tf.gather(pred, 5, axis=2)\n",
    "y1, y2, y3 = tf.gather(pred, 0, axis=2), tf.gather(pred, 1, axis=2), tf.gather(pred, 2, axis=2)\n",
    "x1, x2, x3 = tf.gather(pred, 3, axis=2), tf.gather(pred, 4, axis=2), tf.gather(pred, 5, axis=2)\n",
    "\n",
    "pred_angles = tf.concat([tf.expand_dims(tf.atan2(y1, x1), 2), \n",
    "                         tf.expand_dims(tf.atan2(y2, x2), 2), \n",
    "                         tf.expand_dims(tf.atan2(y3, x3), 2)], axis=2)\n",
    "pred_angles = tf.reshape(pred_angles, (batch_size, protein_length, 3))\n",
    "# pred_angles = tf.where(tf.is_nan(pred_angles), tf.zeros_like(pred_angles), pred_angles)\n",
    "tf.summary.histogram(\"pred_angles\", pred_angles)\n",
    "\n",
    "# choose a loss (mse or mae)\n",
    "loss = tf.losses.mean_squared_error(labels=tf.concat([dih_y, dih_x], axis=2), predictions=pred)\n",
    "# tf.summary.histogram(\"loss\", loss)\n",
    "\n",
    "angle_loss = tf.losses.mean_squared_error(labels=(dihedral_angles), predictions=pred_angles)\n",
    "tf.summary.histogram(\"angle_loss\", angle_loss)\n",
    "\n",
    "# learning rate placeholder for adaptive learning rate\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "# choose an optimizer to minimize the loss\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(angle_loss, global_step=global_step)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate = learning_rate).minimize(angle_loss)\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "# Get the gradients\n",
    "gvs = optimizer.compute_gradients(angle_loss)\n",
    "# Clip gradients (except gradients from the dense layer)\n",
    "capped_gvs = [\n",
    "    (tf.clip_by_norm(grad, 2.), var) if not \n",
    "    var.name.startswith(\"dense\") else (grad, var)\n",
    "    for grad, var in gvs]\n",
    "# Apply Gradients (Update Trainable Variables) \n",
    "optimizer = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-9cc25a962805>:16: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9cc25a962805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             (summary, _, dihedral_angles_, labels_, \n\u001b[1;32m     41\u001b[0m              \u001b[0mpred_angles_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_loss_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m              batch_size_, pred_) = sess.run([merge, optimizer, dihedral_angles, labels, \n\u001b[0m\u001b[1;32m     43\u001b[0m                                              \u001b[0mpred_angles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                              batch_size, pred], \n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the main training loop.\n",
    "\n",
    "The coord calls and try, exceptm, finally instructions are due to the way Queues operate.\n",
    "They use a coordinator and queue_runners to load the data asynchronously to the actual computations.\n",
    "\"\"\"\n",
    "logdir = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/train\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # important to call both of these, because \n",
    "    # otherwise can't specify num_epochs in string_input_producer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()  \n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter( logdir, sess.graph)\n",
    "\n",
    "    try:\n",
    "        # we can't access information from the queue\n",
    "        # to know when an epoch ends, so we define our\n",
    "        # own step counter and calculate an average loss every n steps\n",
    "        step = 1\n",
    "        \n",
    "        losses = []\n",
    "        angle_losses = []\n",
    "        avg_losses = []\n",
    "        avg_angle_losses=[]\n",
    "        \n",
    "        samples_through_counter = 0\n",
    "        epochs_counter = 0\n",
    "        \n",
    "        while not coord.should_stop():  \n",
    "            merge = tf.summary.merge_all()\n",
    "#             (_, dihedral_angles_, labels_, pred_, \n",
    "#              pred_angles_, loss_, angle_loss_) = sess.run([optimizer, dihedral_angles, labels, pred, \n",
    "#                                                            pred_angles, loss, angle_loss], \n",
    "#                                                                feed_dict={learning_rate: 0.01})\n",
    "            (summary, _, dihedral_angles_, labels_, \n",
    "             pred_angles_, angle_loss_,\n",
    "             batch_size_, pred_) = sess.run([merge, optimizer, dihedral_angles, labels, \n",
    "                                             pred_angles, angle_loss,\n",
    "                                             batch_size, pred], \n",
    "                                             feed_dict={learning_rate: 0.001})\n",
    "\n",
    "#             losses.append(loss_)\n",
    "            angle_losses.append(angle_loss_)\n",
    "            if step % 10 == 0:\n",
    "#                 avg_loss =  np.mean(losses)\n",
    "                avg_angle_loss = np.mean(angle_losses)\n",
    "#                 avg_losses.append(avg_loss)\n",
    "                avg_angle_losses.append(avg_angle_loss)\n",
    "#                 print(\"Avg loss:\", avg_loss)\n",
    "                print(\"Avg angle loss:\", avg_angle_loss)\n",
    "#                 print(\"Angle loss:\", angle_loss_)\n",
    "                print(\"Std:\", np.std(angle_losses))\n",
    "\n",
    "                losses = []\n",
    "                angle_losses = []\n",
    "            \n",
    "            samples_through_counter += batch_size_\n",
    "            if samples_through_counter > training_samples * (epochs_counter+1):\n",
    "                print(\"EPOCH\")\n",
    "                epochs_counter += 1\n",
    "            \n",
    "            train_writer.add_summary(summary, step)\n",
    "            step += 1\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "\n",
    "        # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.14156, 3.1415927, -2.2531586, 3.1387393)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dihedral_angles_), np.max(dihedral_angles_), np.min(pred_angles_), np.max(pred_angles_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the avg losses over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(avg_losses)\n",
    "plt.plot(avg_angle_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get just the dihedral angles to see if they resemble how a ramachadran plot should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()  \n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "    \n",
    "#     dihedral_angles_, euclidean_coordinates_, all_4_len_slices_euc_coord_ = sess.run([dihedral_angles, \n",
    "#                                                                                       euclidean_coordinates, \n",
    "#                                                                                       all_4_len_slices_euc_coord                                                                                     \n",
    "#                                                                                     ])\n",
    "    labels_mask_, x1_, x2_, x3_, y1_, y2_, y3_, pred_, pred_angles_, dihedral_angles_  = sess.run([labels_mask, x1, x2, x3, y1, y2, y3, pred, pred_angles, dihedral_angles])\n",
    "#     pred_ = sess.run([pred_c])\n",
    "    coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 516, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dihedral_angles_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 789),\n",
       " (32, 789),\n",
       " (32, 789),\n",
       " (32, 789),\n",
       " (32, 789, 6),\n",
       " (32, 789, 3),\n",
       " (32, 789, 3),\n",
       " 9.444581)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_.shape, y2_.shape, y3_.shape, x3_.shape, pred_.shape, pred_angles_.shape, dihedral_angles_.shape, angle_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[   0. ],\n",
       "         [   0. ],\n",
       "         [   0. ]],\n",
       " \n",
       "        [[4515.9],\n",
       "         [4011.4],\n",
       "         [5703. ]],\n",
       " \n",
       "        [[4639.6],\n",
       "         [4043.6],\n",
       "         [5626.4]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0. ],\n",
       "         [   0. ],\n",
       "         [   0. ]],\n",
       " \n",
       "        [[   0. ],\n",
       "         [   0. ],\n",
       "         [   0. ]],\n",
       " \n",
       "        [[   0. ],\n",
       "         [   0. ],\n",
       "         [   0. ]]], dtype=float32), array([[[   0. ,    0. ,    0. ],\n",
       "         [4515.9, 4011.4, 5703. ],\n",
       "         [4639.6, 4043.6, 5626.4],\n",
       "         [4608.7, 4049.5, 5477.2]],\n",
       " \n",
       "        [[4515.9, 4011.4, 5703. ],\n",
       "         [4639.6, 4043.6, 5626.4],\n",
       "         [4608.7, 4049.5, 5477.2],\n",
       "         [4548. , 3942.8, 5425.9]],\n",
       " \n",
       "        [[4639.6, 4043.6, 5626.4],\n",
       "         [4608.7, 4049.5, 5477.2],\n",
       "         [4548. , 3942.8, 5425.9],\n",
       "         [4505. , 3936.9, 5286.2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ]],\n",
       " \n",
       "        [[   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ]],\n",
       " \n",
       "        [[   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ],\n",
       "         [   0. ,    0. ,    0. ]]], dtype=float32), array([[-0.25348714,  3.0816522 , -1.538865  ],\n",
       "        [-0.08465115, -3.0919905 , -1.3822418 ],\n",
       "        [ 2.2193382 ,  3.0607564 , -1.8549333 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]], dtype=float32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_coordinates_[0][2:], all_4_len_slices_euc_coord_[0][2:], dihedral_angles_[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 637, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dihedral_angles_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = tf_rad2deg(np.array(dihedral_angles_)[:,:,0])\n",
    "beta = tf_rad2deg(np.array(dihedral_angles_)[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-180, 180)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUHBQEREUDAQEREUDEREBAUDEREB/j8gYno7nwKrbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14dfab349b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(beta[9], alpha[9], s=2)\n",
    "plt.xlim((-180,180))\n",
    "plt.ylim((-180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
